{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to load data to BigQuery\n",
    "\n",
    "Demonstrate a few different ways to load data to BigQuery from a Python 3 notebook.\n",
    "* [bq](https://cloud.google.com/bigquery/docs/bq-command-line-tool) command line tool\n",
    "* [gcloud python client](https://googleapis.github.io/google-cloud-python/latest/bigquery/usage/index.html#bigquery-basics)\n",
    "* [pandas-gbq](https://pandas-gbq.readthedocs.io/en/latest/)\n",
    "\n",
    "For files, the `bq` tool or the gcloud-python-client are great and work the same. Choose whichever one you like more.\n",
    "\n",
    "For dataframes in memory, the pandas-gbq client is a great way to go (no need to write it out to a file first)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "First, be sure to run notebook **`Python environment setup`** in this workspace.\n",
    "\n",
    "Then in this section we:\n",
    "\n",
    "1. load the needed python packages\n",
    "2. set some constants to be used as parameters to our BigQuery load jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-user/.local/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/home/jupyter-user/.local/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import LoadJobConfig\n",
    "from google.cloud.bigquery import SchemaField\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit these global variables in your clone of this notebook if you do not have permission to WRITE data to this native Google Cloud Platform project.\n",
    "* The destination BigQuery dataset should already exist. Your pet account must have WRITE access to it.\n",
    "* The remaining cells can be run as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE VARIABLES, IF NEEDED\n",
    "DESTINATION_PROJECT_ID = 'terra-resources'\n",
    "DESTINATION_DATASET = 'autodelete_after_one_day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BILLING_PROJECT_ID = os.environ['GOOGLE_PROJECT']\n",
    "CSV_PATH = 'gs://genomics-public-data/platinum-genomes/other/platinum_genomes_sample_info.csv'\n",
    "# Also try this CSV which will yield some autodetect errors.\n",
    "# gs://genomics-public-data/1000-genomes/other/sample_info/sample_info.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data to BigQuery from a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Via the `bq` command line tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION_TABLE = 'py3_bq_' + time.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Waiting on bqjob_r2884fe21606a321f_0000016fa0b724d0_1 ... (0s) Current status: RUNNING\r",
      "                                                                                      \r",
      "Waiting on bqjob_r2884fe21606a321f_0000016fa0b724d0_1 ... (1s) Current status: RUNNING\r",
      "                                                                                      \r",
      "Waiting on bqjob_r2884fe21606a321f_0000016fa0b724d0_1 ... (2s) Current status: RUNNING\r",
      "                                                                                      \r",
      "Waiting on bqjob_r2884fe21606a321f_0000016fa0b724d0_1 ... (2s) Current status: DONE   "
     ]
    }
   ],
   "source": [
    "%%bash -s \"$DESTINATION_PROJECT_ID\" \"$DESTINATION_DATASET\" \"$DESTINATION_TABLE\" \"$CSV_PATH\"\n",
    "\n",
    "bq --project ${1} load --autodetect ${2}.${3} ${4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the table schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table terra-resources:autodelete_after_one_day.py3_bq_20200113_210233\n",
      "\n",
      "   Last modified                  Schema                 Total Rows   Total Bytes     Expiration      Time Partitioning   Clustered Fields   Labels  \n",
      " ----------------- ------------------------------------ ------------ ------------- ----------------- ------------------- ------------------ -------- \n",
      "  13 Jan 21:02:38   |- Catalog_ID: string                17           1441          14 Jan 21:02:38                                                  \n",
      "                    |- Description: string                                                                                                           \n",
      "                    |- Gender: string                                                                                                                \n",
      "                    |- Race: string                                                                                                                  \n",
      "                    |- Family_Member: integer                                                                                                        \n",
      "                    |- Relationship_to_Proband: string                                                                                               \n",
      "                    |- CT_Desc: string                                                                                                               \n",
      "                    |- Cum_Pdl: string                                                                                                               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$DESTINATION_PROJECT_ID\" \"$DESTINATION_DATASET\" \"$DESTINATION_TABLE\"\n",
    "\n",
    "bq --project ${1} show ${2}.${3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Via the gcloud Python client\n",
    "\n",
    "https://googlecloudplatform.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.LoadJobConfig.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=os.environ['GOOGLE_PROJECT'])\n",
    "DESTINATION_TABLE = 'py3_gcloud_py_client_' + time.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading py3_gcloud_py_client_20200113_210249, starting job 045b9df5-6258-41d3-b7ad-e9d578065dc6\n"
     ]
    }
   ],
   "source": [
    "table_ref = client.dataset(DESTINATION_DATASET,\n",
    "                           project=DESTINATION_PROJECT_ID).table(DESTINATION_TABLE)\n",
    "\n",
    "# https://googlecloudplatform.github.io/google-cloud-python/latest/bigquery/generated/google.cloud.bigquery.job.LoadJobConfig.html\n",
    "job_config = LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.autodetect = True\n",
    "\n",
    "load_job = client.load_table_from_uri(CSV_PATH, table_ref, job_config=job_config)\n",
    "print('Loading {}, starting job {}'.format(DESTINATION_TABLE, load_job.job_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job finished.\n"
     ]
    }
   ],
   "source": [
    "# Waits for table load to complete.\n",
    "load_job.result()\n",
    "print('Job finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_job.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SchemaField('Catalog_ID', 'STRING', 'NULLABLE', None, ()), SchemaField('Description', 'STRING', 'NULLABLE', None, ()), SchemaField('Gender', 'STRING', 'NULLABLE', None, ()), SchemaField('Race', 'STRING', 'NULLABLE', None, ()), SchemaField('Family_Member', 'INTEGER', 'NULLABLE', None, ()), SchemaField('Relationship_to_Proband', 'STRING', 'NULLABLE', None, ()), SchemaField('CT_Desc', 'STRING', 'NULLABLE', None, ()), SchemaField('Cum_Pdl', 'STRING', 'NULLABLE', None, ())]\n"
     ]
    }
   ],
   "source": [
    "table = client.get_table(table_ref)  # API Request\n",
    "print(table.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(table.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(table.num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data to BigQuery from a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Via pandas-gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION_TABLE = 'py3_pandas_gbq_' + time.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(low=0, high=10, size=(5, 5)),\n",
    "                  columns=['a', 'b', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.91s/it]\n"
     ]
    }
   ],
   "source": [
    "df.to_gbq(destination_table='.'.join([DESTINATION_DATASET, DESTINATION_TABLE]),\n",
    "          project_id=DESTINATION_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1/1 [00:00<00:00,  7.43rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cnt\n",
       "0    5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.io.gbq.read_gbq('SELECT COUNT(*) AS cnt FROM `{}.{}.{}`'.format(DESTINATION_PROJECT_ID,\n",
    "                                                                   DESTINATION_DATASET,\n",
    "                                                                   DESTINATION_TABLE),\n",
    "                   project_id=BILLING_PROJECT_ID,\n",
    "                   dialect='standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 21:03:08.622710\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-api-core==1.15.0\r\n",
      "google-auth-oauthlib==0.4.1\r\n",
      "google-cloud-bigquery==1.23.1\r\n",
      "google-cloud-core==1.1.0\r\n",
      "ibis-framework==1.2.0\r\n",
      "multipledispatch==0.6.0\r\n",
      "oauthlib==3.1.0\r\n",
      "pandas==0.25.3\r\n",
      "pandas-gbq==0.13.0\r\n",
      "pydata-google-auth==0.2.1\r\n",
      "regex==2020.1.8\r\n",
      "requests-oauthlib==1.3.0\r\n",
      "six==1.13.0\r\n",
      "toolz==0.10.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2018 The Broad Institute, Inc., Verily Life Sciences, LLC All rights reserved.\n",
    "\n",
    "This software may be modified and distributed under the terms of the BSD license. See the LICENSE file for details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
